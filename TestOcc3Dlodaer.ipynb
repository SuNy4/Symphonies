{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Color Map\n",
    "# colors_map = np.array(\n",
    "#     [\n",
    "#         [0,   0,   0, 255],  # 0 undefined\n",
    "#         [255, 158, 0, 255],  # 1 car  orange\n",
    "#         [0, 0, 230, 255],    # 2 pedestrian  Blue\n",
    "#         [47, 79, 79, 255],   # 3 sign  Darkslategrey\n",
    "#         [220, 20, 60, 255],  # 4 CYCLIST  Crimson\n",
    "#         [255, 69, 0, 255],   # 5 traiffic_light  Orangered\n",
    "#         [255, 140, 0, 255],  # 6 pole  Darkorange\n",
    "#         [233, 150, 70, 255], # 7 construction_cone  Darksalmon\n",
    "#         [255, 61, 99, 255],  # 8 bycycle  Red\n",
    "#         [112, 128, 144, 255],# 9 motorcycle  Slategrey\n",
    "#         [222, 184, 135, 255],# 10 building Burlywood\n",
    "#         [0, 175, 0, 255],    # 11 vegetation  Green\n",
    "#         [165, 42, 42, 255],  # 12 trunk  nuTonomy green\n",
    "#         [0, 207, 191, 255],  # 13 curb, road, lane_marker, other_ground\n",
    "#         [75, 0, 75, 255], # 14 walkable, sidewalk\n",
    "#         [255, 0, 0, 255], # 15 unobsrvd\n",
    "#         [0, 0, 0, 0],  # 16 undefined\n",
    "#         [0, 0, 0, 0],  # 16 undefined\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test Dataloader: Load data\n",
    "from ssc_pl.data.datasets.semantic_kitti import *\n",
    "from ssc_pl.data.datasets.occ3d import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "kittidata = './data/kitti/dataset'\n",
    "kittilabel = './data/kitti/dataset/dataset/labels'\n",
    "kittidepth = './data/kitti/dataset/dataset/depth'\n",
    "dataroot = './data/nuscenes'\n",
    "\n",
    "dataset = Occ3D(split = 'train', data_root=dataroot)\n",
    "kitti = SemanticKITTI(split='val', data_root=kittidata, label_root=kittilabel, depth_root=kittidepth)\n",
    "#dataset = DataLoader(data, batch_size=16, shuffle=True)\n",
    "\n",
    "data, label = dataset[0]\n",
    "ex_data = data['cam_channels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SemanticKITTI example\n",
    "# from ssc_pl.models.utils import (cumprod, flatten_fov_from_voxels, flatten_multi_scale_feats, generate_grid,\n",
    "#                      get_level_start_index, index_fov_back_to_voxels, interpolate_flatten,\n",
    "#                      nchw_to_nlc, nlc_to_nchw, pix2vox)\n",
    "# image_shape = (370, 1220)\n",
    "# image_grid = generate_grid(image_shape)\n",
    "# image_grid = torch.flip(image_grid, dims=[0]).unsqueeze(0)\n",
    "# depth = kitdat['depth'].unsqueeze(0)\n",
    "# ### bs x 900 x 1600\n",
    "\n",
    "# K = kitdat['cam_K'].unsqueeze(0)\n",
    "# ### bs x 3 x 3\n",
    "\n",
    "# E = kitdat['cam_pose'].unsqueeze(0)\n",
    "# voxel_origin = kitdat['voxel_origin'].unsqueeze(0)\n",
    "# vol_pts_kit = pix2vox(\n",
    "#     image_grid,\n",
    "#     depth.unsqueeze(0),\n",
    "#     K,\n",
    "#     E,\n",
    "#     voxel_origin,\n",
    "#     0.2,\n",
    "#     downsample_z=2).long()\n",
    "\n",
    "# scene_size = (256, 256, 32) ## in voxel pixels\n",
    "# points = vol_pts_kit\n",
    "# keep = ((points[..., 0] >= 0) & (points[..., 0] < scene_size[0]) &\n",
    "#         (points[..., 1] >= 0) & (points[..., 1] < scene_size[1]) &\n",
    "#         (points[..., 2] >= 0) & (points[..., 2] < scene_size[2]))\n",
    "# assert points.shape[0] == 1\n",
    "# geom = points.squeeze()[keep.squeeze()]\n",
    "# kitti_pts_mask = torch.zeros(scene_size, dtype=torch.bool)\n",
    "# kitti_pts_mask[geom[:, 0], geom[:, 1], geom[:, 2]] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## KITTI- Visualize depth to voxel\n",
    "# from pythreejs import *\n",
    "# import numpy as np\n",
    "# from IPython.display import display\n",
    "\n",
    "# # pts_mask\n",
    "# h, w, z = torch.nonzero(kitti_pts_mask, as_tuple=True)  \n",
    "# kitti_points = torch.stack((h, w, z), dim=-1).numpy()\n",
    "\n",
    "# pcd_geometry = BufferGeometry(\n",
    "#     attributes={\n",
    "#         'position': BufferAttribute(kitti_points, normalized=False),\n",
    "#         #'color': BufferAttribute(colors, normalized=False),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# material = PointsMaterial(color='blue', size=0.5)\n",
    "# scene_data = Points(geometry=pcd_geometry, material=material)\n",
    "# # scene = Scene(children=[\n",
    "# #     scene_data,\n",
    "# #     AmbientLight(color='#cccccc'),\n",
    "# #     DirectionalLight(color='white', position=[3, 5, 1], intensity=0.5)\n",
    "# # ])\n",
    "# scene = Scene(children=[\n",
    "#     scene_data,\n",
    "#     AmbientLight(color='#cccccc'),\n",
    "#     DirectionalLight(color='white', position=[3, 5, 1], intensity=0.5)\n",
    "# ])\n",
    "\n",
    "# camera = PerspectiveCamera(position=[0, 100, 0], fov=75, near=0.1)\n",
    "# camera.up = [0, 1, 0]\n",
    "\n",
    "# controller = OrbitControls(controlling=camera)\n",
    "\n",
    "# renderer = Renderer(camera=camera, scene=scene, controls=[controller], width=800, height=800)\n",
    "\n",
    "# display(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Sample Image from data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "img = np.array(ex_data['CAM_FRONT']['img'], dtype=np.float32)\n",
    "\n",
    "img = img * std[:, None, None] + mean[:, None, None]\n",
    "img = (img * 255).astype(np.uint8)\n",
    "img = img.transpose(1, 2, 0)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing voxel proposal - get voxel from depth data\n",
    "\n",
    "from ssc_pl.models.utils import (cumprod, flatten_fov_from_voxels, flatten_multi_scale_feats, generate_grid,\n",
    "                     get_level_start_index, index_fov_back_to_voxels, interpolate_flatten,\n",
    "                     nchw_to_nlc, nlc_to_nchw, pix2vox)\n",
    "\n",
    "image_shape = (900, 1600)\n",
    "image_grid = generate_grid(image_shape)\n",
    "image_grid = torch.flip(image_grid, dims=[0]).unsqueeze(0)\n",
    "#image_grid = torch.flip(image_grid, dims=[3])\n",
    "### bs x 2 x 900 x 1600\n",
    "voxel_origin = np.array((-40, -40, -2)) # in meters (Width Depth Height)\n",
    "voxel_origin = torch.from_numpy(voxel_origin).unsqueeze(0)\n",
    "### bs x 3\n",
    "\n",
    "voxel_size = 0.4\n",
    "vol_pts = []\n",
    "\n",
    "for cam in ex_data:\n",
    "    depth = ex_data[cam]['depth'].unsqueeze(0)\n",
    "    #depth = torch.flip(depth, dims = [1])\n",
    "    ### bs x 900 x 1600\n",
    "\n",
    "    K = ex_data[cam]['cam_K'].unsqueeze(0)\n",
    "    ### bs x 3 x 3\n",
    "\n",
    "    E = ex_data[cam]['cam_pose'].unsqueeze(0)\n",
    "    ### bs x 4 x 4\n",
    "\n",
    "    vol_pts_cam = pix2vox(\n",
    "        image_grid,\n",
    "        depth.unsqueeze(0),\n",
    "        K,\n",
    "        E,\n",
    "        voxel_origin,\n",
    "        voxel_size,\n",
    "        downsample_z=1).long()\n",
    "\n",
    "    min_h = torch.min(vol_pts_cam[:, :, 2])\n",
    "    vol_pts_cam[:, :, 2] -= min_h\n",
    "    vol_pts.append(vol_pts_cam)\n",
    "    ### bs x HW x 3\n",
    "\n",
    "points = torch.cat(vol_pts, dim=1)\n",
    "\n",
    "\n",
    "scene_size = (200, 200, 16) ## in voxel pixels\n",
    "keep = ((points[..., 0] >= 0) & (points[..., 0] < scene_size[0]) &\n",
    "        (points[..., 1] >= 0) & (points[..., 1] < scene_size[1]) &\n",
    "        (points[..., 2] >= 0) & (points[..., 2] < scene_size[2]))\n",
    "assert points.shape[0] == 1\n",
    "geom = points.squeeze()[keep.squeeze()]\n",
    "pts_mask = torch.zeros(scene_size, dtype=torch.bool)\n",
    "pts_mask[geom[:, 0], geom[:, 1], geom[:, 2]] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize depth to voxel\n",
    "from pythreejs import *\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# pts_mask\n",
    "h, w, z = torch.nonzero(pts_mask, as_tuple=True)  \n",
    "points = torch.stack((h, w, z), dim=-1).numpy()\n",
    "print(points.shape)\n",
    "pcd_geometry = BufferGeometry(\n",
    "    attributes={\n",
    "        'position': BufferAttribute(points, normalized=False),\n",
    "        #'color': BufferAttribute(colors, normalized=False),\n",
    "    }\n",
    ")\n",
    "\n",
    "material = PointsMaterial(color='blue', size=0.5)\n",
    "scene_data = Points(geometry=pcd_geometry, material=material)\n",
    "# scene = Scene(children=[\n",
    "#     scene_data,\n",
    "#     AmbientLight(color='#cccccc'),\n",
    "#     DirectionalLight(color='white', position=[3, 5, 1], intensity=0.5)\n",
    "# ])\n",
    "scene = Scene(children=[\n",
    "    scene_data,\n",
    "    AmbientLight(color='#cccccc'),\n",
    "    DirectionalLight(color='white', position=[3, 5, 1], intensity=0.5)\n",
    "])\n",
    "\n",
    "camera = PerspectiveCamera(position=[0, 0, 100], fov=75, near=0.1)\n",
    "camera.up = [0, 0, 1]\n",
    "\n",
    "controller = OrbitControls(controlling=camera)\n",
    "\n",
    "renderer = Renderer(camera=camera, scene=scene, controls=[controller], width=500, height=500)\n",
    "\n",
    "display(renderer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render GT label\n",
    "gt = label['target']\n",
    "\n",
    "gt = gt * np.array(pts_mask)\n",
    "boolean_tensor = gt != 0\n",
    "\n",
    "x, y, z = np.nonzero(boolean_tensor)  \n",
    "points = np.stack((x, y, z)).T\n",
    "\n",
    "geometry = BufferGeometry(\n",
    "    attributes={\n",
    "        'position': BufferAttribute(points, normalized=False),\n",
    "    }\n",
    ")\n",
    "\n",
    "material = PointsMaterial(vertexColors='VertexColors', size=1)\n",
    "point_cloud = Points(geometry=geometry, material=material)\n",
    "\n",
    "scene = Scene(children=[\n",
    "    point_cloud,\n",
    "    AmbientLight(color='#cccccc'),\n",
    "    DirectionalLight(color='white', position=[3, 5, 1], intensity=0.5)\n",
    "])\n",
    "\n",
    "# camera = PerspectiveCamera(position=[-100, 0, 0], fov=75, near=0.1, far=1000)\n",
    "# camera.up = [0, 0, 1]\n",
    "\n",
    "# controller = OrbitControls(controlling=camera)\n",
    "\n",
    "renderer = Renderer(camera=camera, scene=scene, controls=[controller], width=500, height=500)\n",
    "\n",
    "renderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Render Raw depth points\n",
    "# vol_pts = []\n",
    "# for i in range(6):\n",
    "#     points = np.load(f'points_{i}.npy')\n",
    "#     vol_pts.append(points)\n",
    "\n",
    "\n",
    "# colors = np.zeros_like(points)\n",
    "\n",
    "# scene_data = []\n",
    "# for i in range(len(vol_pts)):\n",
    "#     points = vol_pts[i].squeeze()\n",
    "\n",
    "#     colors = np.zeros_like(points)\n",
    "\n",
    "#     pcd_geometry = BufferGeometry(\n",
    "#         attributes={\n",
    "#             'position': BufferAttribute(points, normalized=False),\n",
    "#             'color': BufferAttribute(colors, normalized=False),\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "\n",
    "#     material = PointsMaterial(vertexColors='VertexColors', size=0.5)\n",
    "#     scene_data.append(Points(geometry=pcd_geometry, material=material))\n",
    "# scene = Scene(children=[\n",
    "#     *scene_data,\n",
    "#     AmbientLight(color='#cccccc'),\n",
    "#     DirectionalLight(color='white', position=[3, 5, 1], intensity=0.5)\n",
    "# ])\n",
    "\n",
    "# camera = PerspectiveCamera(position=[0, 0, 100], fov=75)\n",
    "# camera.up = [0, -1, 0]\n",
    "\n",
    "# controller = OrbitControls(controlling=camera)\n",
    "\n",
    "# renderer = Renderer(camera=camera, scene=scene, controls=[controller], width=1000, height=800)\n",
    "\n",
    "# renderer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
